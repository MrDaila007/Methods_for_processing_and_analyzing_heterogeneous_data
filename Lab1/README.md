# Лабораторная работа 1 — Предобработка, моделирование и контроль дрейфа на Titanic

## Общее
Работа посвящена пунктам 2–6: импутации пропусков, выявлению и фильтрации выбросов, масштабированию признаков, сравнению классификационных и регрессионных пайплайнов и оценке дрейфа на табличных данных (Titanic и Iris).

## Файлы
- `Lab1/data/Titanic-Dataset.csv`
- `Lab1/data/Iris.csv`
- `Lab1/lab1.py`: скрипт для перебора пайплайнов, кросс-валидации и KS-отчета по дрейфу.

## Наборы данных
1. `Titanic` — классификация `survived`, регрессия `fare`.
2. `Iris` — классификация `species`, регрессия `petal_length`.

## Требования
Пользуйтесь тем же окружением, что и в корневом README; установите зависимости при необходимости:

```bash
/home/user/Documents/LABS_MAGA/Methods_for_processing_and_analyzing_heterogeneous_data/.conda/bin/python -m pip install pandas scikit-learn scipy seaborn
```

## Запуск

```bash
/home/user/Documents/LABS_MAGA/Methods_for_processing_and_analyzing_heterogeneous_data/.conda/bin/python Lab1/lab1.py
```

Вывод содержит:
1. **Таблицу классификации** (accuracy/precision/recall/F1) для каждой комбинации импутер + фильтр + скейлер.
2. **Таблицу регрессии** (RMSE/MAE/R²) для предсказания `fare`.
3. **Отчет KS-теста** по числовым признакам между двумя стратифицированными частями.
4. **Сводку лучших пайплайнов** для классификации и регрессии.

## Выбор набора
Скрипт принимает опцию `--dataset` (или `-d`): укажите ID из списка выше, например:

```bash
python Lab1/lab1.py --dataset 2
```

Дополнительно можно передать `--max-rows 2000`, чтобы ограничить объем обрабатываемых данных (полезно для больших CSV).

Для ускорения попробуйте `--use-gpu`, если в среде установлены библиотеки cuML; иначе CPU.

## Сравниваемые методы
- импутация: `mean`, `median`, `knn`, `most_frequent`, `constant_zero`, `iterative`, `drop`;
- фильтрация выбросов: `none`, `winsorization`, `log`, `boxcox`, `yeojohnson`;
- масштабирование: `none`, `standard`, `minmax`, `robust`, `quantile`, `unit_vector`.

## Пример результатов
Последняя прогонка (Titanic) показала:

| Задача | Импутер | Выбросы | Скейлер | Метрика | Значение |
| --- | --- | --- | --- | --- | --- |
| Классификация | `median` | `iqr` | `minmax` | Accuracy | 0.808 |
| Регрессия | `mean` | `iqr` | `none` | RMSE | 34.514 |
| Дрейф | — | — | — | Ни один из `age`, `sibsp`, `fare`, `parch`, `pclass` не дрейфил (p ≥ 0.05) | |

## Визуализации
Скрипт сохраняет графики в `Lab1/figures/`:

- `missing_values.png` — гистограмма доли пропусков по столбцам.
- `iqr_outlier_distributions.png` — KDE-наложение «сырых» vs IQR-очищенных распределений.
- `outlier_metric_comparison.png` — сравнение accuracy/RMSE по стратегиям очистки выбросов.
- `numeric_correlation_heatmap.png` — матрица корреляций для числовых признаков.
- `feature_survival_boxplot.png` — боксплоты `age` и `fare` в разрезе выживаемости.

## Полная статистика
Все комбинации предобработок записываются в `Lab1/results/` для каждого набора:

- `Lab1/results/classification_full_<ID>.csv`
- `Lab1/results/regression_full_<ID>.csv`

Можно использовать эти файлы для более глубокого анализа, не ограничиваясь только лучшими результатами.

## Ноутбук
`Lab1/lab1_analysis.ipynb` повторяет этот пайплайн в интерактивном режиме: импортирует `lab1`, запускает перебор, показывает отчет по дрейфу и отображает сохраненные графики.

## Условия лабораторной работы
1. Для задачи классификации или регрессии выберите табличный набор (либо синтетически сгенерированный, либо искаженный исходный). Пункты 2-4 можно реализовывать для разных наборов.
2. Реализуйте работу с пропусками.
3. Реализуйте детектирование выбросов.
4. Реализуйте масштабирование признаков.
5. Постройте модель и на тесте сравните эффективность разных методов из пунктов 2-4 (таблицы, релевантные метрики, кросс-валидация).
6. Выполните оценку дрейфа данных.

## Что делать дальше
1. Сохраните таблицы (например, перенаправьте вывод `lab1.py` в Markdown) для отчета.
2. Визуализируйте влияние каждой предобработки на метрики.
3. Расширьте оценку дрейфа (например, индекс стабильности популяции) при появлении новых данных.
